model:
  model_class: BatchRNN
  model_setting:
    embedding_size: 512
    hidden_size: 512
    num_layers: 2
    vocab_size: 700
    
    loss_type: MapeLoss
    pad_idx: from:data.special_token_idx.PAD

train:
  seed: 3431
  batch_size: 4
  val_batch_size: 4
  n_epochs: 30
  clip_grad_norm:  0.2
  optimizer: SGD
  optimizer_setting:
    lr: 0.5
    momentum: 0.9
  use_batch_step_lr: false
  lr_scheduler: get_decay_after_delay_lr_sched
  lr_scheduler_setting:
    delay: 2
    div_factor: 1.2
  hyperparameter_testing:
    using: False
    mult: 0.2
  gradient_accumlation:
    using: false
    steps: 256
data:
  # data_file: training_data/spec_core_0714.data
  data_file: training_data/intel_core.data
  # src_info_file: training_data/skl_mapping.csv
  data_setting:
    bert: false
    only_unique: true
    split_mode: num_instrs
    train_perc: 8
    val_perc: 2
    test_perc: 0
    prepare_mode: stacked
    shuffle: true
    instr_limit: 400
    custom_idx_split: saved/SR:B/0831/idx_dict.dump
    given_token_mapping: null
  dataset_class: StackedBlockDataset
  dataset_setting:
    too_long_limit: 512
  # raw_data: false
  #  sample usage of predifined special token idxs
  special_token_idx:
    PAD: 0
    BLOCK_START: 1
    BLOCK_END: 2
    START: 3
    END: 4  
    SEP: 5
    UNK: 6 
    MSK: 7
    # PAD: 0
    # SRCS: 1
    # DSTS: 2
    # MEM: 3 # <MEM>
    # MEM_FIN: 4  # </MEM>
    # END: 5
    # UNK: 6 
    