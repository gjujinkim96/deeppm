model:
  model_class: NonStacked2
  model_setting:
    dim: 512
    n_heads: 8
    dim_ff: 2048
    pred_drop: 0.0
    vocab_size: 700
    loss_type: MapeLoss
    num_basic_block_layer: 2
    num_op_layer: 2
    # use_checkpoint: false
    # checkpoint_cnt: 1
    pad_idx: from:data.special_token_idx.PAD
    op_idx: from:data.special_token_idx.OP
    srcs_idx: from:data.special_token_idx.SRCS
    dsts_idx: from:data.special_token_idx.DSTS
train:
  seed: 3431
  batch_size: 32
  val_batch_size: 32
  n_epochs: 30
  clip_grad_norm: 0.2
  optimizer: Adam
  optimizer_setting:
    lr: 0.0001
    # weight_decay: 0.0001
  lr_scheduler: LinearLR
  use_batch_step_lr: false
  lr_scheduler_setting:
    total_iters: 5
  hyperparameter_testing:
    using: False
    mult: 0.2



data:
  data_file: training_data/spec_core_0714.data
  # src_info_file: training_data/skl_mapping.csv
  data_setting:
    bert: false
    only_unique: true
    split_mode: none
    train_perc: 8
    val_perc: 2
    test_perc: 0
    prepare_mode: non_stacked_extra_tags
    shuffle: false
    instr_limit: 2
  dataset_class: BasicBlockDataset
  dataset_setting:
    too_long_limit: 512
  # raw_data: false
  #  sample usage of predifined special token idxs
  # special_token_idx:
  #   PAD: 0
  #   SRCS: 1
  #   DSTS: 2
  #   MEM: 3 # <MEM>
  #   /MEM: 4  # </MEM>
  #   START: 5
  #   END: 6
  #   UNK: 7 
  #   OP: 8
  #   BASE: 9
  #   INDEX: 10
  #   DISP: 11
  #   SCALE: 12

    